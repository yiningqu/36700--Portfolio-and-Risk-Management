{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b2f936",
   "metadata": {},
   "source": [
    "# Midterm 1\n",
    "\n",
    "## FINM 36700 - 2023\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28e7fd",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd63ff",
   "metadata": {},
   "source": [
    "## Please note the following:\n",
    "\n",
    "Points\n",
    "* The exam is 100 points.\n",
    "* You have 120 minutes to complete the exam.\n",
    "* For every minute late you submit the exam, you will lose one point.\n",
    "Final Exam\n",
    "\n",
    "Submission\n",
    "* You will upload your solution to the `Midterm 1` assignment on Canvas, where you downloaded this. (Be sure to **submit** on Canvas, not just **save** on Canvas.\n",
    "* Your submission should be readable, (the graders can understand your answers,) and it should **include all code used in your analysis in a file format that the code can be executed.** \n",
    "\n",
    "Rules\n",
    "* The exam is open-material, closed-communication.\n",
    "* You do not need to cite material from the course github repo--you are welcome to use the code posted there without citation.\n",
    "\n",
    "Advice\n",
    "* If you find any question to be unclear, state your interpretation and proceed. We will only answer questions of interpretation if there is a typo, error, etc.\n",
    "* The exam will be graded for partial credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960a3c5",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**All data files are found in the class github repo, in the `data` folder.**\n",
    "\n",
    "This exam makes use of the following data files:\n",
    "* `midterm_data_1.xlsx`\n",
    "\n",
    "This file has sheets for...\n",
    "* `info` - names of each stock ticker\n",
    "* `excess returns` - weekly excess returns on several stocks\n",
    "* `SPY` - weekly excess returns on SPY\n",
    "\n",
    "Note the data is **weekly** so any annualizations should use `52` weeks in a year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f6568",
   "metadata": {},
   "source": [
    "#### If useful\n",
    "here is code to load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "344abdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILEIN = '../data/midterm_1_data.xlsx'\n",
    "# sheet_exrets = 'excess returns'\n",
    "# sheet_spy = 'spy'\n",
    "\n",
    "# retsx = pd.read_excel(FILEIN, sheet_name=sheet_exrets).set_index('date')\n",
    "# spy = pd.read_excel(FILEIN, sheet_name=sheet_spy).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af33e1",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "| Problem | Points |\n",
    "|---------|--------|\n",
    "| 1       | 20     |\n",
    "| 2       | 35     |\n",
    "| 3       | 30     |\n",
    "| 4       | 15     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158c236",
   "metadata": {},
   "source": [
    "### Each numbered question is worth 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362090a7",
   "metadata": {},
   "source": [
    "### Notation\n",
    "(Hidden LaTeX commands)\n",
    "\n",
    "$$\\newcommand{\\mux}{\\tilde{\\boldsymbol{\\mu}}}$$\n",
    "$$\\newcommand{\\wtan}{\\boldsymbol{\\text{w}}^{\\text{tan}}}$$\n",
    "$$\\newcommand{\\wtarg}{\\boldsymbol{\\text{w}}^{\\text{port}}}$$\n",
    "$$\\newcommand{\\mutarg}{\\tilde{\\boldsymbol{\\mu}}^{\\text{port}}}$$\n",
    "$$\\newcommand{\\wEW}{\\boldsymbol{\\text{w}}^{\\text{EW}}}$$\n",
    "$$\\newcommand{\\wRP}{\\boldsymbol{\\text{w}}^{\\text{RP}}}$$\n",
    "$$\\newcommand{\\wREG}{\\boldsymbol{\\text{w}}^{\\text{REG}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40926a81",
   "metadata": {},
   "source": [
    "# 1. Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c0d60",
   "metadata": {},
   "source": [
    "### No Data Needed\n",
    "\n",
    "These problem does not require any data file. Rather, analyze the situation conceptually, based on the information below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086f971",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "In what sense was ProShares `HDG` successful in hedging the `HFRI`, and in what sense was it unsuccessful in tracking the `HFRI`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4045b",
   "metadata": {},
   "source": [
    "HDG is successful in hedging the HFRI when there is negative correlation between HDG and HFRI's return in the market. Also, when the alpha is large, the hedging process is successful. \n",
    "\n",
    "HDG is unseccessful in tracking the HFRI when it deviates from positions if they can get additional returns or reduce transaction cost. When the tracking error is high, it is unseccessful. When the alpha value is large, the tracking is unsuccessful. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ddf91",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "We discussed multiple ways of calculating Value-at-Risk (VaR). What are the tradeoffs between using the normal distribution formula versus a directly empirical approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e4b9a",
   "metadata": {},
   "source": [
    "Calculating VaR using normal distribution will gain statistical power for the result. For example, there are only 50 datapoints and we want to see the VaR at quantile 0.01. There is no such point that can be estimated in the sample, or the sample size is too limited. Therefore, assuming normal distribution gives the result in more statistical way. However, when the data is not normally distributed, it causes some problems because it overestimate or underestimate the value of VaR.\n",
    "\n",
    "Calculating VaR using directly empirical approach is great when there is a huge dataset and the sample for quantile 0.05 and 0.01 is enough to estimate. When there are limited sample data to estimate, it loses statistical power in estimating VaR. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b7e68",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Did we find that **TIPS** have been useful in expanding the mean-variance frontier in the past? Did we conclude they might be useful in the future? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475b9852",
   "metadata": {},
   "source": [
    "Somewhat yes. TIPS has relatively low correlation with other assets. When TIP is involved in the mean-variance frontier calculation, the Sharpe Ratio is relatively higher (changes from 1.930 to 1.933). However, it does not changes significantly, which means that the inclusion of TIPS or not does not significantly affect the mean-variance frontier. It is very useful in the future, because when you expect TIPS to grow or downgrade in the future, it will have significant impact on the mean-variance frontier. For example, when expected excess return to TIPS is adjusted to be 0.0012 higher than what the historic sample shows, the sharpe ratio increases from 1.930 to 2.031 with lower volatility, and the weights are completely different. Dropping TIPS from the investment set barely impacts the weights or the resulting performance. Adjusting the mean of TIPS upward even just 1 standard error substantially impacts the allocations and moderately boosts the resulting performance. Based on just a mean-variance analysis, it seems one could reasonably go either way with TIPS as an alternate asset class. In the argument to keep it separate, there is more diversification between TIPS and bonds than between SPY and many other equity buckets Harvard has. On the other hand, TIPS mostly impact the allocation to domestic bonds and might be seen as another asset in that bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97348b",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "What aspect of the classic mean-variance optimization approach leads to extreme answers? How did regularization help with this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc1100",
   "metadata": {},
   "source": [
    "mean-variance optimization approach leads to extreme answers because when the number of assets is really large, the correlation between assets are large. In order to minimize the volatility, it will long and short assets with high correlation with extremely large leveraging scale. Estimation Errors: One of the main challenges with mean-variance optimization is the sensitivity of the approach to the input estimates, especially expected returns, variances, and covariances of the assets. Small changes or errors in input estimates can lead to vastly different portfolio weights, and in many cases, extreme portfolio allocations (i.e., very large or very small weights, even negative weights in certain unconstrained optimizations. Inverse of the Covariance Matrix: The optimization process involves the inversion of the covariance matrix. If this matrix is nearly singular (i.e., has a determinant close to zero), or if it's ill-conditioned, it can lead to extreme asset weights. This problem is exacerbated when dealing with a large number of assets, some of which might be closely correlated. Regularization introduces a penalty on the magnitude of portfolio weights, especially when trying to estimate parameters in a statistical model. It helps in constraining or shrinking the estimates towards more stable solutions.Ridge (L2) and Lasso (L1) Regularization: These are the most common techniques used to introduce regularization in portfolio optimization. Ridge regularization tends to shrink the coefficients toward zero but doesn't set any of them exactly to zero. Lasso regularization can shrink some coefficients to exactly zero, effectively selecting a subset of assets for the portfolio. This can be useful in creating sparse portfolios. Regularization helps in producing more stable portfolio weights that are less sensitive to small changes in input estimates. Especially with L1 regularization, the resulting portfolios tend to be simpler, with fewer assets having non-zero weights, which can aid in interpretability and practicality (e.g., reduced transaction costs). Regularization helps in preventing overfitting to the sample data, which is particularly crucial when dealing with financial data that can be noisy. Bayesian Approaches: Another form of regularization comes from Bayesian methods, where prior beliefs about asset returns can be combined with observed data to create more stable posterior estimates. This acts as a form of regularization by pulling extreme estimates towards more reasonable values based on prior beliefs. In essence, regularization provides a tool to address the sensitivity and instability issues inherent in classic mean-variance optimization, allowing for more practical and robust portfolio solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8991015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from functools import partial\n",
    "import sys\n",
    "import math\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e42346",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66389e",
   "metadata": {},
   "source": [
    "# 2. Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b67603",
   "metadata": {},
   "source": [
    "Consider a mean-variance optimization of **excess** returns provided in `midterm_1_data.xlsx.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe496df",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Report the following **annualized** statistics:\n",
    "* mean\n",
    "* volatility\n",
    "* Sharpe ratio\n",
    "\n",
    "Which assets have the highest / lowest Sharpe ratios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8391a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEIN = '/Users/yiningqu/Desktop/midterm_1_data.xlsx'\n",
    "\n",
    "sheet_exrets = 'excess returns'\n",
    "sheet_spy = 'spy'\n",
    "\n",
    "retsx = pd.read_excel(FILEIN, sheet_name=sheet_exrets).set_index('date')\n",
    "spy = pd.read_excel(FILEIN, sheet_name=sheet_spy).set_index('date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fde202d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL    0.3194\n",
      "MSFT    0.2881\n",
      "AMZN    0.2395\n",
      "NVDA    0.6507\n",
      "GOOGL   0.1933\n",
      "TSLA    0.5697\n",
      "XOM     0.1242\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "annualized_mean = retsx.mean()*52\n",
    "print(annualized_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "076e33ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL    0.2839\n",
      "MSFT    0.2402\n",
      "AMZN    0.3104\n",
      "NVDA    0.4681\n",
      "GOOGL   0.2742\n",
      "TSLA    0.6070\n",
      "XOM     0.3116\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "annualized_std = retsx.std()* math.sqrt(52)\n",
    "print(annualized_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c02682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL    1.1252\n",
      "MSFT    1.1993\n",
      "AMZN    0.7715\n",
      "NVDA    1.3900\n",
      "GOOGL   0.7050\n",
      "TSLA    0.9386\n",
      "XOM     0.3986\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sharpe_ratio = annualized_mean / annualized_std\n",
    "print(sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "400b09a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset class with highest sharpe ratio is  NVDA\n",
      "Asset class with lowest sharpe ratio is  XOM\n"
     ]
    }
   ],
   "source": [
    "sr_array = np.array(sharpe_ratio)\n",
    "sr_max = retsx.columns[np.argmax(sr_array)]\n",
    "sr_min = retsx.columns[np.argmin(sr_array)]\n",
    "print('Asset class with highest sharpe ratio is ', sr_max)\n",
    "print('Asset class with lowest sharpe ratio is ', sr_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f091c84",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "Report the weights of the tangency portfolio.\n",
    "\n",
    "Also report the Sharpe ratio achieved by the tangency portfolio over this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c00c486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tangent Weight</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.3226</td>\n",
       "      <td>1.1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.7875</td>\n",
       "      <td>1.1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>-0.2286</td>\n",
       "      <td>0.7715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.4960</td>\n",
       "      <td>1.3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>-0.5027</td>\n",
       "      <td>0.7050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.9386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.3986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tangent Weight  Sharpe Ratio\n",
       "AAPL           0.3226        1.1252\n",
       "MSFT           0.7875        1.1993\n",
       "AMZN          -0.2286        0.7715\n",
       "NVDA           0.4960        1.3900\n",
       "GOOGL         -0.5027        0.7050\n",
       "TSLA           0.1060        0.9386\n",
       "XOM            0.0193        0.3986"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix = retsx.cov()\n",
    "inv_cov = np.linalg.inv(cov_matrix)\n",
    "mean = np.array(annualized_mean)\n",
    "n_1 = np.transpose(np.ones(7))\n",
    "w_tan = (1/(n_1@inv_cov@mean))*(inv_cov@mean)\n",
    "w_tan_summary = pd.DataFrame(np.array([w_tan,sr_array]).T, columns= [\"Tangent Weight\",\"Sharpe Ratio\"], index= retsx.columns)\n",
    "w_tan_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bab65",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "* What weight is given to the asset with the lowest Sharpe ratio?\n",
    "* What Sharpe ratio does the lowest (most negative) weight asset have?\n",
    "\n",
    "Explain. Support your answer with evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b71acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of the asset with the lowest Sharpe ratio is  0.019256607953705398\n",
      "Sharpe ratio of lowest (most negative) weight asset is  0.705019854216037\n"
     ]
    }
   ],
   "source": [
    "w_min_sr = w_tan_summary.loc[w_tan_summary['Sharpe Ratio'].idxmin()]['Tangent Weight']\n",
    "sr_min_w = w_tan_summary.loc[w_tan_summary['Tangent Weight'].idxmin()]['Sharpe Ratio']\n",
    "\n",
    "\n",
    "print('The weight of the asset with the lowest Sharpe ratio is ', w_min_sr)\n",
    "print('Sharpe ratio of lowest (most negative) weight asset is ', sr_min_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131963d5",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Let's examine the out-of-sample performance.\n",
    "\n",
    "Calculate and report the following three allocations using only data through the end of 2022:\n",
    "* tangency portfolio\n",
    "* equally weighted portfolio\n",
    "* a regularized approach, with a new formula shown below\n",
    "\n",
    "where\n",
    "$$\\wEW_i = \\frac{1}{n}$$\n",
    "\n",
    "$$\\wREG \\sim \\widehat{\\Sigma}^{-1}\\mux$$\n",
    "\n",
    "$$\\widehat{\\Sigma} = \\frac{\\Sigma + \\boldsymbol{2}\\,\\Sigma_D}{\\boldsymbol{3}}$$\n",
    "where $\\Sigma_D$ denotes a *diagonal* matrix of the security variances, with zeros in the off-diagonals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2df317fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "excess_returns_IS = retsx[:'2022'].reset_index()\n",
    "excess_returns_OOS = retsx['2023':].reset_index()\n",
    "\n",
    "excess_returns_in_sample = excess_returns_IS[excess_returns_IS.columns[1:]] \n",
    "excess_returns_out_of_sample = excess_returns_OOS[excess_returns_OOS.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ab637d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Vol</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "      <th>VaR (0.05)</th>\n",
       "      <th>CVaR (0.05)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tangency</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tangency with TIPS dropped</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tangency with TIPS adjusted</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal weights</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk parity</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularized</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Mean  Vol Sharpe   Min   Max Skewness  \\\n",
       "tangency                     NaN  NaN    NaN  None  None      NaN   \n",
       "tangency with TIPS dropped   NaN  NaN    NaN  None  None      NaN   \n",
       "tangency with TIPS adjusted  NaN  NaN    NaN  None  None      NaN   \n",
       "equal weights                NaN  NaN    NaN  None  None      NaN   \n",
       "risk parity                  NaN  NaN    NaN  None  None      NaN   \n",
       "regularized                  NaN  NaN    NaN  None  None      NaN   \n",
       "\n",
       "                            Excess Kurtosis  VaR (0.05) CVaR (0.05)  \n",
       "tangency                                NaN         NaN         NaN  \n",
       "tangency with TIPS dropped              NaN         NaN         NaN  \n",
       "tangency with TIPS adjusted             NaN         NaN         NaN  \n",
       "equal weights                           NaN         NaN         NaN  \n",
       "risk parity                             NaN         NaN         NaN  \n",
       "regularized                             NaN         NaN         NaN  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary_statistics_annualized(returns, annual_factor = 52):\n",
    "    \"\"\"This functions returns the summary statistics for the input total/excess returns passed\n",
    "    into the function\"\"\"\n",
    "    \n",
    "    summary_statistics = pd.DataFrame(index=returns.columns)\n",
    "    summary_statistics['Mean'] = returns.mean() * annual_factor\n",
    "    summary_statistics['Vol'] = returns.std() * np.sqrt(annual_factor)\n",
    "    summary_statistics['Sharpe'] = (returns.mean() / returns.std()) * np.sqrt(annual_factor)\n",
    "    summary_statistics['Min'] = returns.min()\n",
    "    summary_statistics['Max'] = returns.max()\n",
    "    summary_statistics['Skewness'] = returns.skew()\n",
    "    summary_statistics['Excess Kurtosis'] = returns.kurtosis()\n",
    "    summary_statistics['VaR (0.05)'] = returns.quantile(.05, axis = 0)\n",
    "    summary_statistics['CVaR (0.05)'] = returns[returns <= returns.quantile(.05, axis = 0)].mean()\n",
    "    \n",
    "    return summary_statistics\n",
    "\n",
    "\n",
    "wts_IS = pd.DataFrame(index = excess_returns_IS.columns[1:], columns = ['tangency','tangency with TIPS dropped',\n",
    "                                                                      'tangency with TIPS adjusted','equal weights',\n",
    "                                                                      'risk parity','regularized'])\n",
    "summary_statistics_annualized(excess_returns_out_of_sample @ wts_IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "57591292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>volatility</th>\n",
       "      <th>sharpe ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equally weighted</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.5924</td>\n",
       "      <td>0.6280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean  volatility  sharpe ratio\n",
       "Equally weighted 1.0000      1.5924        0.6280"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mean = 1\n",
    "#Equally-weighted (EW)\n",
    "ew = pd.DataFrame()\n",
    "weight1 = np.full((retsx.shape[1],1), 1/retsx.shape[1])\n",
    "#np.full((number of rows, number of columns),each entry value)\n",
    "mean = weight1.T @ np.array(retsx.mean() * 12)\n",
    "\n",
    "variance = weight1.T @ retsx.cov() @ weight1\n",
    "\n",
    "vol = math.sqrt(variance.iloc[0, 0]) *math.sqrt(12)\n",
    "\n",
    "sharpe_ratio = mean / vol\n",
    "\n",
    "rescale1 = target_mean / mean\n",
    "\n",
    "ew['mean'] = mean * rescale1\n",
    "ew['volatility'] = vol * rescale1\n",
    "ew['sharpe ratio'] = sharpe_ratio\n",
    "ew.index = ['Equally weighted']\n",
    "ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f27f5f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>volatility</th>\n",
       "      <th>sharpe ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Regularized</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.4108</td>\n",
       "      <td>0.7088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  volatility  sharpe ratio\n",
       "Regularized 1.0000      1.4108        0.7088"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Regularized (REG)\n",
    "reg = pd.DataFrame()\n",
    "\n",
    "cov_matrix = np.array(retsx.cov()) \n",
    "sigma_d = np.diag(np.diag(cov_matrix))\n",
    "matrix = (cov_matrix + sigma_d)/2\n",
    "weight3 = np.linalg.inv(matrix) @ np.array(retsx.mean() * 12)\n",
    "scale = 1/weight3.sum()\n",
    "weight_reg = (weight3 * scale)\n",
    "\n",
    "mean = weight_reg.T @ np.array(retsx.mean() * 12) \n",
    "\n",
    "variance = weight_reg.T @ retsx.cov() @ weight_reg\n",
    "vol = math.sqrt(variance) *math.sqrt(12)\n",
    "\n",
    "sharpe_ratio = mean / vol\n",
    "\n",
    "rescale2 = target_mean / mean\n",
    "\n",
    "reg['mean'] = [mean * rescale2]\n",
    "reg['volatility'] = [vol * rescale2]\n",
    "reg['sharpe ratio'] = [sharpe_ratio]\n",
    "reg.index = ['Regularized']\n",
    "reg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255bdd",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "Report the out-of-sample (2023) performance of all three portfolios in terms of annualized mean, vol, and Sharpe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70301de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f65554c5",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "Imagine just for this problem that this data is for **total** returns, not excess returns.\n",
    "\n",
    "Report the weights of the global-minimum-variance portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ba3845ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.4912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>-0.1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>-0.0469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.2964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight\n",
       "AAPL   0.2062\n",
       "MSFT   0.4912\n",
       "AMZN   0.1609\n",
       "NVDA  -0.1192\n",
       "GOOGL  0.0114\n",
       "TSLA  -0.0469\n",
       "XOM    0.2964"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_cov = np.linalg.inv(cov_matrix)  # Assuming cov_matrix is your covariance matrix\n",
    "ones_vector = np.ones(inv_cov.shape[0])\n",
    "global_min_var_weights = inv_cov @ ones_vector / (ones_vector.T @ inv_cov @ ones_vector)\n",
    "global_min_var = pd.DataFrame(global_min_var_weights, index=retsx.columns, columns=[\"weight\"])\n",
    "global_min_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41a996",
   "metadata": {},
   "source": [
    "## 7.\n",
    "\n",
    "To target a mean return of 0.005%, would you be long or short this global minimum variance portfolio?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ed308",
   "metadata": {},
   "source": [
    "I would long this global minimum variance portfolio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cdbfa9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d9fbd",
   "metadata": {},
   "source": [
    "# 3. Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426af123",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Report the following performance metrics of excess returns for Tesla (`TSLA`).\n",
    "* skewness\n",
    "* kurtosis\n",
    "\n",
    "You are not annualizing any of these stats.\n",
    "\n",
    "What do these metrics indicate about the nature of the returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28f6cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telsa skewness is: 0.44145458268186166\n",
      "Telsa kurtosis is: 1.5273762473269983\n"
     ]
    }
   ],
   "source": [
    "skewness = retsx[\"TSLA\"].skew()\n",
    "kurtosis = retsx[\"TSLA\"].kurtosis()\n",
    "print(f'Telsa skewness is: {skewness}')\n",
    "print(f'Telsa kurtosis is: {kurtosis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50356f76",
   "metadata": {},
   "source": [
    "Skewness of tesla is positive. Skewness measures the degree of asymmetry or lack of symmetry in the distribution of a dataset. It quantifies the direction and amount of skew (departure from horizontal symmetry). Skewness is positive means that it has high probability of small losses and with smaller probability with big returns.  positive skewness indicates a distribution that is skewed to the right (or has a right tail), meaning that the right tail is longer than the left tail. Here, the mean is typically greater than the median.\n",
    "\n",
    "Kurtosis measures the \"tailedness\" of a distribution, that is, the sharpness of the peak and the heaviness of the tails. It quantifies whether the data has heavy or light tails relative to a normal distribution. Kurtosis is less than 3 means that the distribution has thinner tails and a more rounded peak than the normal distribution. It suggests a lower occurrence of extreme values than expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877253fc",
   "metadata": {},
   "source": [
    "## 2. \n",
    "\n",
    "Report the maximum drawdown for `TSLA` over the sample.\n",
    "* Ignore that your data is in excess returns rather than total returns.\n",
    "* Simply proceed with the excess return data for this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "327f8d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maximum drawdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.3721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>-0.2995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>-0.4681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>-0.5923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>-0.3483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>-0.6822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>-0.6714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Maximum drawdown\n",
       "AAPL            -0.3721\n",
       "MSFT            -0.2995\n",
       "AMZN            -0.4681\n",
       "NVDA            -0.5923\n",
       "GOOGL           -0.3483\n",
       "TSLA            -0.6822\n",
       "XOM             -0.6714"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1000*(1+retsx).cumprod()\n",
    "previous_peaks = index.cummax()\n",
    "drawdowns = ((index - previous_peaks)/previous_peaks)\n",
    "max_drawdown = drawdowns.min()  \n",
    "maxdrawdown = pd.DataFrame(max_drawdown, columns = [\"Maximum drawdown\"])\n",
    "maxdrawdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d77a74",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "For `TSLA`, calculate the following metrics, relative to `SPY`:\n",
    "* market beta\n",
    "* alpha\n",
    "* sortino ratio\n",
    "\n",
    "Annualize alpha and sortino ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7251648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market beta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>sortino ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>1.7768</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>1.6423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       market beta  alpha  sortino ratio\n",
       "Tesla       1.7768 0.3095         1.6423"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regression(regressor, regressand,  period=52, multiple=False, alpha=True):\n",
    "    X = sm.tools.add_constant(regressor) if alpha else regressor   #加constant to regression model\n",
    "\n",
    "    model = sm.OLS(regressand, X, missing='drop').fit()  #run regression\n",
    "\n",
    "    if alpha:\n",
    "        if multiple==False:\n",
    "            beta = model.params.iloc[1]\n",
    "            alpha = model.params.loc['const'] *52\n",
    "\n",
    "    else:   \n",
    "        beta = model.params\n",
    "    \n",
    "    sortino_ratio = retsx['TSLA'].mean() / retsx['TSLA'][retsx['TSLA'] < 0].std() * math.sqrt(52)\n",
    "    \n",
    "    return beta, alpha, sortino_ratio #如果没有alpha则没有information ratio\n",
    "\n",
    "\n",
    "beta,alpha,sortino_ratio  = regression(spy, retsx['TSLA'])\n",
    "data = {\n",
    "    \"market beta\": [beta],\n",
    "    \"alpha\": [alpha],\n",
    "    \"sortino ratio\": [sortino_ratio]\n",
    "}\n",
    "TSLA = pd.DataFrame(data, index=[\"Tesla\"])\n",
    "TSLA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7919b2",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Continuing with `TSLA`, calculate the full-sample, 5th-percentile CVaR.\n",
    "* Use the `normal` formula, assuming mean returns are zero.\n",
    "* Use the full-sample volatility.\n",
    "\n",
    "Use the entire sample to calculate a single CVaR number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f44eef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.241549307100958"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = retsx['TSLA'].std() * math.sqrt(52)\n",
    "CVaR = 0 - vol * norm.pdf(-1.65) / 0.05\n",
    "CVaR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94065e1d",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "Now calculate the 5th-percentile, one-period ahead, **VaR** for `TSLA`.\n",
    "\n",
    "Here, calculate the running series of VaR estimates.\n",
    "\n",
    "Again, \n",
    "* use the normal formula, with mean zero.\n",
    "\n",
    "But now, use the rolling volatility, based on \n",
    "* rolling window or $m=52$ weeks.\n",
    "\n",
    "Report the final 5 values of your calculated VaR series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec17a2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of VaR smaller than 0 in the next 5 weeks: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def prob(mu, sigma, h):\n",
    "    return norm.cdf(-np.sqrt(h)*mu/sigma)\n",
    "\n",
    "\n",
    "VaR = retsx['TSLA'].shift(1).expanding(min_periods = 52).quantile(0.05)\n",
    "VaR_mu = VaR.mean()\n",
    "VaR_sigma = VaR.std()\n",
    "\n",
    "probability = prob(mu=VaR_mu, sigma=VaR_sigma, h=5)\n",
    "print('Probability of VaR smaller than 0 in the next 5 weeks: {:,.2%}'.\n",
    "      format(probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a30cac",
   "metadata": {},
   "source": [
    "## 6. \n",
    "\n",
    "Calculate the out-of-sample **hit ratio** for your VaR series reported in your previous answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "43ef7d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit ratio is 1.0\n"
     ]
    }
   ],
   "source": [
    "hit_ratio = 5*probability / 5\n",
    "print(f'hit ratio is {hit_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee2bb2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3820d1b",
   "metadata": {},
   "source": [
    "# 4. Hedging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b559f9a9",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Consider the following scenario: you are holding a \\$100 million long position in `NVDA`. You wish to hedge the position using some combination of \n",
    "* `AAPL`\n",
    "* `AMZN`\n",
    "* `GOOGL`\n",
    "* `MSFT`\n",
    "\n",
    "Report the positions you would hold of those 4 securities for an optimal hedge.\n",
    "\n",
    "Note:\n",
    "* In the regression estimation, include an intercept.\n",
    "* Use the full-sample regression. No need to worry about in-sample versus out-of-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6b86eb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.3417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.4173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>-0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.5879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.2738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefficient\n",
       "AAPL        0.3417\n",
       "AMZN        0.4173\n",
       "GOOGL      -0.0078\n",
       "MSFT        0.5879\n",
       "const       0.2738"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regression(regressor, regressand, period=52, multiple=False, alpha=True):\n",
    "    X = sm.tools.add_constant(regressor) if alpha else regressor   #加constant to regression model\n",
    "\n",
    "    model = sm.OLS(regressand, X, missing='drop').fit()  #run regression\n",
    "\n",
    "    if alpha:\n",
    "        beta = model.params.iloc[1:]    #Question2只有一个factor SPY所以beta只有一个，但在其他时候会有别的regressor\n",
    "        alpha = model.params.loc['const'] * period\n",
    "    else:   \n",
    "        beta = model.params\n",
    "    \n",
    "    tracking_er_vol = (model.resid.std() * np.sqrt(period)) \n",
    "\n",
    "    return beta, alpha, model.rsquared,tracking_er_vol #如果没有alpha则没有information ratio\n",
    "\n",
    "beta, alpha, r_squared, tracking_error = regression(\n",
    "        retsx[['AAPL','AMZN','GOOGL','MSFT']], retsx['NVDA'])\n",
    "coefficients = pd.DataFrame(index= ['AAPL','AMZN','GOOGL','MSFT'], columns=['coefficient'])\n",
    "coefficients['coefficient'] = beta\n",
    "coefficients.loc['const'] =  alpha\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bfeeb261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>34,168,648.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>41,725,985.8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>-784,795.2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>58,789,673.0294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Positions\n",
       "AAPL  34,168,648.9989\n",
       "AMZN  41,725,985.8798\n",
       "GOOGL   -784,795.2478\n",
       "MSFT  58,789,673.0294"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hedge = pd.DataFrame(index= ['AAPL','AMZN','GOOGL','MSFT'], columns=['Positions'])\n",
    "hedge['Positions'] = 100000000 * beta\n",
    "hedge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127f366",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "How well does the hedge do? Cite a regression statistic to support your answer.\n",
    "\n",
    "Also estimate the volatility of the basis, (epsilon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd5a1e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4581682361155385\n",
      "0.34456153441586174\n"
     ]
    }
   ],
   "source": [
    "print(r_squared)\n",
    "print(tracking_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e2257",
   "metadata": {},
   "source": [
    "The beta sizes are all very realistic, with none of the betas being above \"1\" or below \"-1\". We also don't have extreme long/short positions, which is good. The largest beta size is 0.5879 which is still can be acceptable. However, the R^2 is relatively low which means the hedge is less effective, as the independent variable(s) can explain a smaller proportion of the variability in the dependent variable. The tracking_error value is large, A large tracking error indicates that the hedge is effective, as the investors can trade on the portion of NVDA uncorrelated with four equities, and this portion is large. It does well in the hedging positions,because betas are realistic and tracking error is high. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b6394",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "Report the annualized intercept. By including this intercept, what are you assuming about the nature of the returns of `NVDA` as well as the returns of the hedging instruments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "15678d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.3417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.4173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>-0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.5879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.2738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefficient\n",
       "AAPL        0.3417\n",
       "AMZN        0.4173\n",
       "GOOGL      -0.0078\n",
       "MSFT        0.5879\n",
       "const       0.2738"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = pd.DataFrame(index= ['AAPL','AMZN','GOOGL','MSFT'], columns=['coefficient'])\n",
    "coefficients['coefficient'] = beta\n",
    "coefficients.loc['const'] =  alpha\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca623197",
   "metadata": {},
   "source": [
    "holding the returns of the hedging instruments constant, NVDA is expected to outperform by 27.38% annually, based purely on the constant term. The intercept essentially captures any systematic performance of NVDA that isn't captured by its relationship with the hedging instruments. If the intercept were zero, it would imply that the returns of NVDA can be completely explained by its exposure to the hedging instruments, and there are no other sources of systematic return. A non-zero intercept implies that there's an additional return component for NVDA that isn't accounted for by its relationship with the hedging instruments. For example, GOOGL has nearly zero intercept which means returns of NVDA can be completely explained by its exposure to the GOOGL. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
